{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bnunicodenormalizer in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (0.0.19)\n"
     ]
    }
   ],
   "source": [
    "# install bnunicodenormalizer\n",
    "!pip install bnunicodenormalizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (1.3.3)\n",
      "Requirement already satisfied: bleach>=3.1.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (4.1.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (7.6.5)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (4.64.0)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (5.9.1)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (2.1.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (1.4.3)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (2022.7.1)\n",
      "Requirement already satisfied: parso>0.4.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from swifter) (0.8.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from bleach>=3.1.1->swifter) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from bleach>=3.1.1->swifter) (21.3)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.22.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.3.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (8.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (5.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (3.5.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipywidgets>=7.0.0->swifter) (6.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from pandas>=1.0.0->swifter) (2022.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from tqdm>=4.33.0->swifter) (0.4.5)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (7.2.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (1.5.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (1.5.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (61.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (5.1.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (2.11.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (3.0.20)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (4.4.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (2.15.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from packaging->bleach>=3.1.1->swifter) (3.0.4)\n",
      "Requirement already satisfied: locket in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (6.4.12)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (0.18.0)\n",
      "Requirement already satisfied: pyzmq>=22.3 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (23.2.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (0.4)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (302)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (3.0.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.13.1)\n",
      "Requirement already satisfied: nbconvert>=5 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (6.4.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.8.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.0.0->swifter) (0.2.2)\n",
      "Requirement already satisfied: testpath in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (4.11.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.5.13)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.1.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.3.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\.conda\\envs\\dlsr\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install swifter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### imports necessaries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm  # for progress bar for iterative elements\n",
    "\n",
    "from bnunicodenormalizer import Normalizer\n",
    "bnorm = Normalizer()\n",
    "\n",
    "import swifter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the data and find unique unicodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# load train and validation data [n.b. csv files]\n",
    "train_df = pd.read_csv('../data/given/train.csv')\n",
    "train_df = train_df[['sentence']]\n",
    "\n",
    "val_df = pd.read_csv('../data/given/validation.csv')\n",
    "val_df = val_df[['sentence']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total sentences:  214697\n"
     ]
    }
   ],
   "source": [
    "sens = train_df['sentence'].tolist() + val_df['sentence'].tolist()\n",
    "print('Number of total sentences: ', len(sens))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/214697 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2698a2e2d02423ebcca96929e232190"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non normalized vocab(unicodes): [total: 90]\n",
      "\n",
      "\n",
      "' ', '!', ''', ',', '-', '.', '/', ':', ';', '=', '?', 'A', 'B', 'V', '©', '।', '॥', 'ঁ', 'ং', 'ঃ', \n",
      "\n",
      "'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', \n",
      "\n",
      "'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', \n",
      "\n",
      "'ষ', 'স', 'হ', '়', 'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ', '্', 'ৎ', 'ড়', 'ঢ়', 'য়', 'ৰ', \n",
      "\n",
      "'৵', '৷', '–', '—', '‘', '’', '‚', '“', '”', '…', "
     ]
    }
   ],
   "source": [
    "# Non normalized vocabularies (unicodes)\n",
    "vocab = []\n",
    "\n",
    "for sen in tqdm(sens):\n",
    "    sen = sen.replace('\"', '')\n",
    "    for c in sen:\n",
    "        if c not in vocab:\n",
    "            vocab.append(c)\n",
    "\n",
    "non_norm_vocab = sorted(vocab)\n",
    "\n",
    "print(\"Non normalized vocab(unicodes): [total: {}]\".format(len(non_norm_vocab)))\n",
    "for index, vocab in enumerate(non_norm_vocab):\n",
    "    if not index % 20: print('\\n')\n",
    "    print(\"'{}'\".format(vocab), end=', ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unicodes that look the same, but are not same"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of '–':  82\n",
      "Index of '—':  83\n",
      "Are they same? :  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Index of '–': \", non_norm_vocab.index('–'))\n",
    "print(\"Index of '—': \", non_norm_vocab.index('—'))\n",
    "print(\"Are they same? : \", '–' == '—')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of '।':  15\n",
      "Index of '৷':  81\n",
      "Are they same? :  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Index of '।': \", non_norm_vocab.index('।'))\n",
    "print(\"Index of '৷': \", non_norm_vocab.index('৷'))\n",
    "print(\"Are they same? : \", '।' == '৷')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of ',':  3\n",
      "Index of '‚':  86\n",
      "Are they same? :  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Index of ',': \", non_norm_vocab.index(','))\n",
    "print(\"Index of '‚': \", non_norm_vocab.index('‚'))\n",
    "print(\"Are they same? : \", ',' == '‚')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "But the most dangerous thing in this text is _Nukta_ '্'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of Nukta:  74\n"
     ]
    }
   ],
   "source": [
    "print(\"Index of Nukta: \", non_norm_vocab.index('্'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* What is this Nukta '্' mean, after breaking the word?\n",
    "* Let's consider an example: 'কেন্দ্রীয়'=='কেন্দ্রীয়'\n",
    "    * Both look the same... are they?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'কেন্দ্রীয়'=='কেন্দ্রীয়'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "But why? ... **Because the first one contains Nukta '্'**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First one:  ['ক', 'ে', 'ন', '্', 'দ', '্', 'র', 'ী', 'য', '়']\n",
      "Second one:  ['ক', 'ে', 'ন', '্', 'দ', '্', 'র', 'ী', 'য়']\n"
     ]
    }
   ],
   "source": [
    "print(\"First one: \", [f for f in 'কেন্দ্রীয়'])\n",
    "print(\"Second one: \", [f for f in 'কেন্দ্রীয়'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalization\n",
    "Now let's solve these problems by normalizing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Normalize method to normalize a single sentence\n",
    "def normalize(sen):\n",
    "    _words = [bnorm(word)['normalized'] for word in sen.split()]\n",
    "    return ' '.join([word for word in _words if word is not None])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/7747 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b8ef667cc604cf9a9fe33f5e1a52f76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/206950 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f317277b43694505abae45b6ab8fd6f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total sentences: 214697\n"
     ]
    }
   ],
   "source": [
    "val_df['sentence'] = val_df['sentence'].swifter.apply(lambda x: normalize(x))\n",
    "train_df['sentence'] = train_df['sentence'].swifter.apply(lambda x: normalize(x))\n",
    "\n",
    "sens = train_df['sentence'].tolist() + val_df['sentence'].tolist()\n",
    "print('Number of total sentences:', len(sens))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/214697 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c4af0741c914fc9907d104fa646c6bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized vocab(unicodes): [total: 74]\n",
      "\n",
      "\n",
      "' ', '!', ''', ',', '-', '.', ':', ';', '=', '?', '।', 'ঁ', 'ং', 'ঃ', 'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', \n",
      "\n",
      "'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', \n",
      "\n",
      "'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ', 'স', 'হ', 'া', 'ি', 'ী', \n",
      "\n",
      "'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ', '্', 'ৎ', 'ড়', 'ঢ়', 'য়', '—', '”', "
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "\n",
    "for sen in tqdm(sens):\n",
    "    sen = sen.replace('\"', '')\n",
    "    for c in sen:\n",
    "        if c not in vocab:\n",
    "            vocab.append(c)\n",
    "\n",
    "norm_vocab = sorted(vocab)\n",
    "\n",
    "print(\"Normalized vocab(unicodes): [total: {}]\".format(len(norm_vocab)))\n",
    "for index, vocab in enumerate(norm_vocab):\n",
    "    if not index % 20: print('\\n')\n",
    "    print(\"'{}'\".format(vocab), end=', ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed symbols: \n",
      "'/', 'A', 'B', 'V', '©', '॥', '়', 'ৰ', '৵', '৷', '–', '‘', '’', '‚', '“', '…', Total removed symbols:  16\n"
     ]
    }
   ],
   "source": [
    "# Removed symbols\n",
    "remove_count = 0\n",
    "print(\"Removed symbols: \")\n",
    "for c in non_norm_vocab:\n",
    "    if c not in norm_vocab:\n",
    "        print(\"'{}'\".format(c), end=', ')\n",
    "        remove_count += 1\n",
    "\n",
    "print(\"Total removed symbols: \", remove_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We will also remove '—' from normalized vocab since '-' has the same functional value\n",
    "* We also have to consider \"\\u200d\" to cover words like - র‍্যাব, \"র‍্যাকেট\", \"র‍্যাশানাল\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "র‍্যাব\n",
      "র‍্যাকেট\n",
      "র‍্যাশানাল\n"
     ]
    }
   ],
   "source": [
    "words = [\"র‍্যাব\", \"র‍্যাকেট\", \"র‍্যাশানাল\"]\n",
    "for word in words:\n",
    "    print(word)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "basically any word that has"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "র‍্য\n"
     ]
    }
   ],
   "source": [
    "print('র'+'\\u200d'+'্'+'য')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "in the text, simply adding 'র'+'্'+'য' result in -"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "র্য\n"
     ]
    }
   ],
   "source": [
    "print('র'+'্'+'য')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "final vocab we can go with (or even remove some puntuations and numbers if we want)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "vocab=[ '\\u200d',\n",
    "        ' ','!',\"'\",',','-','.',':',';','=','?','।',\n",
    "        'ঁ','ং','ঃ',\n",
    "        'অ','আ','ই','ঈ','উ','ঊ','ঋ','এ','ঐ','ও','ঔ',\n",
    "        'ক','খ','গ','ঘ','ঙ',\n",
    "        'চ','ছ','জ','ঝ','ঞ',\n",
    "        'ট','ঠ','ড','ঢ','ণ',\n",
    "        'ত','থ','দ','ধ','ন',\n",
    "        'প','ফ','ব','ভ','ম',\n",
    "        'য','র','ল',\n",
    "        'শ','ষ','স','হ',\n",
    "        'া','ি','ী','ু','ূ','ৃ','ে','ৈ','ো','ৌ','্',\n",
    "        'ৎ','ড়','ঢ়','য়',\n",
    "        '০','১','২','৩','৪','৫','৬','৭','৮','৯']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "to explore non norm text try the following -"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  বায়ান্ন ['ব', 'া', 'য়', 'া', 'ন', '্', 'ন']\n",
      "new text:  বায়ান্ন ['ব', 'া', 'য', '়', 'া', 'ন', '্', 'ন']\n",
      "are they same?:  False\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "text = \"বায়ান্ন\"\n",
    "new_text = unicodedata.normalize('NFKC', text)\n",
    "\n",
    "print(\"text: \", text, [t for t in text])\n",
    "print(\"new text: \", new_text, [t for t in new_text])\n",
    "print(\"are they same?: \", text == new_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "this will cause problem in WER and CER calculation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}